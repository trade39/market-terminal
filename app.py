import streamlit as st
import yfinance as yf
import pandas as pd
import numpy as np
import plotly.graph_objects as go
import plotly.express as px
import requests
import re
from fredapi import Fred
from newsapi import NewsApiClient
import google.generativeai as genai
from datetime import datetime, timedelta
from scipy.interpolate import UnivariateSpline
from scipy.stats import norm

# --- APP CONFIGURATION ---
st.set_page_config(layout="wide", page_title="Market Terminal Pro", page_icon="ğŸ“ˆ")

# Custom CSS
st.markdown("""
<style>
Â  Â  .stApp { background-color: #0e1117; }
Â  Â  .metric-container { background-color: #1e1e1e; border: 1px solid #333; padding: 10px; border-radius: 5px; text-align: center; }
Â  Â  .sentiment-box { padding: 15px; border-radius: 5px; margin-bottom: 20px; border-left: 5px solid #d4af37; background-color: #262730; }
Â  Â Â 
Â  Â  /* Signal badges */
Â  Â  .bullish { color: #00ff00; font-weight: bold; background-color: rgba(0, 255, 0, 0.1); padding: 2px 8px; border-radius: 4px; }
Â  Â  .bearish { color: #ff4b4b; font-weight: bold; background-color: rgba(255, 75, 75, 0.1); padding: 2px 8px; border-radius: 4px; }
Â  Â  .neutral { color: #cccccc; font-weight: bold; background-color: rgba(200, 200, 200, 0.1); padding: 2px 8px; border-radius: 4px; }
Â  Â Â 
Â  Â  /* Volatility Badges */
Â  Â  .vol-go { background-color: rgba(0, 255, 0, 0.2); color: #00ff00; padding: 4px 10px; border-radius: 4px; font-weight: bold; border: 1px solid #00ff00; }
Â  Â  .vol-stop { background-color: rgba(255, 75, 75, 0.2); color: #ff4b4b; padding: 4px 10px; border-radius: 4px; font-weight: bold; border: 1px solid #ff4b4b; }
</style>
""", unsafe_allow_html=True)

# --- CONSTANTS & MAPPINGS ---
ASSETS = {
Â  Â  "S&P 500": {"ticker": "^GSPC", "opt_ticker": "SPY", "news_query": "S&P 500"},
Â  Â  "NASDAQ": {"ticker": "^IXIC", "opt_ticker": "QQQ", "news_query": "Nasdaq"},
Â  Â  "Gold (Comex)": {"ticker": "GC=F", "opt_ticker": "GLD", "news_query": "Gold Price"},
Â  Â  "EUR/USD": {"ticker": "EURUSD=X", "opt_ticker": "FXE", "news_query": "EURUSD"},
Â  Â  "NVIDIA": {"ticker": "NVDA", "opt_ticker": "NVDA", "news_query": "Nvidia Stock"}
}

DXY_TICKER = "DX-Y.NYB"

# --- HELPER FUNCTIONS ---

def get_api_key(key_name):
Â  Â  if "api_keys" in st.secrets and key_name in st.secrets["api_keys"]:
Â  Â  Â  Â  return st.secrets["api_keys"][key_name]
Â  Â  if key_name in st.secrets:
Â  Â  Â  Â  return st.secrets[key_name]
Â  Â  return None

# --- SENTIMENT LOGIC ENGINE ---
def parse_eco_value(val_str):
Â  Â  if not isinstance(val_str, str) or val_str == '': return None
Â  Â  clean = val_str.replace('%', '').replace(',', '')
Â  Â  multiplier = 1.0
Â  Â  if 'K' in clean.upper():
Â  Â  Â  Â  multiplier = 1000.0
Â  Â  Â  Â  clean = clean.upper().replace('K', '')
Â  Â  elif 'M' in clean.upper():
Â  Â  Â  Â  multiplier = 1000000.0
Â  Â  Â  Â  clean = clean.upper().replace('M', '')
Â  Â  elif 'B' in clean.upper():
Â  Â  Â  Â  multiplier = 1000000000.0
Â  Â  Â  Â  clean = clean.upper().replace('B', '')
Â  Â  try:
Â  Â  Â  Â  return float(clean) * multiplier
Â  Â  except:
Â  Â  Â  Â  return None

def analyze_event_impact(event_name, val_main, val_compare, is_actual):
Â  Â  v1 = parse_eco_value(val_main)
Â  Â  v2 = parse_eco_value(val_compare)
Â  Â  if v1 is None or v2 is None: return "Neutral"
Â  Â  usd_logic = {
Â  Â  Â  Â  "CPI": True, "PPI": True, "Non-Farm": True, "GDP": True,Â 
Â  Â  Â  Â  "Sales": True, "Confidence": True, "Rates": True,
Â  Â  Â  Â  "Unemployment": False, "Claims": False
Â  Â  }
Â  Â  is_direct = TrueÂ 
Â  Â  for key, val in usd_logic.items():
Â  Â  Â  Â  if key.lower() in event_name.lower():
Â  Â  Â  Â  Â  Â  is_direct = val
Â  Â  Â  Â  Â  Â  break
Â  Â  delta = v1 - v2
Â  Â  pct_diff = 0
Â  Â  if v2 != 0: pct_diff = abs(delta / v2)
Â  Â  is_percentage_data = "%" in str(val_main)
Â  Â  is_mean_reverting = False
Â  Â  if is_percentage_data and abs(delta) < 0.05: is_mean_reverting = TrueÂ 
Â  Â  elif not is_percentage_data and pct_diff < 0.01: is_mean_reverting = TrueÂ 
Â  Â  if is_mean_reverting: return "Mean Reverting (Neutral)"
Â  Â  if delta > 0: return "USD Bullish" if is_direct else "USD Bearish"
Â  Â  elif delta < 0: return "USD Bearish" if is_direct else "USD Bullish"
Â  Â  return "Mean Reverting"

# --- DATA FETCHING ---

@st.cache_data(ttl=60)
def get_daily_data(ticker):
Â  Â  try:
Â  Â  Â  Â  # UPDATED to 10y for better Seasonality Stats
Â  Â  Â  Â  data = yf.download(ticker, period="10y", interval="1d", progress=False)
Â  Â  Â  Â  return data
Â  Â  except Exception:
Â  Â  Â  Â  return pd.DataFrame()

@st.cache_data(ttl=60)
def get_intraday_data(ticker):
Â  Â  try:
Â  Â  Â  Â  data = yf.download(ticker, period="5d", interval="15m", progress=False)
Â  Â  Â  Â  return data
Â  Â  except Exception:
Â  Â  Â  Â  return pd.DataFrame()

@st.cache_data(ttl=300)
def get_news(api_key, query):
Â  Â  if not api_key: return None
Â  Â  try:
Â  Â  Â  Â  newsapi = NewsApiClient(api_key=api_key)
Â  Â  Â  Â  start_date = (datetime.now() - timedelta(days=28)).strftime('%Y-%m-%d')
Â  Â  Â  Â  articles = newsapi.get_everything(q=query, from_param=start_date, language='en', sort_by='relevancy', page_size=10)
Â  Â  Â  Â  return articles['articles']
Â  Â  except Exception as e:
Â  Â  Â  Â  return f"Error: {str(e)}"

@st.cache_data(ttl=3600)
def get_economic_calendar(api_key):
Â  Â  if not api_key: return None
Â  Â  url = "https://forex-factory-scraper1.p.rapidapi.com/get_calendar_details"
Â  Â  now = datetime.now()
Â  Â  querystring = {
Â  Â  Â  Â  "year": str(now.year), "month": str(now.month), "day": str(now.day),
Â  Â  Â  Â  "currency": "USD", "event_name": "ALL", "timezone": "GMT-05:00 Eastern Time (US & Canada)", "time_format": "12h"
Â  Â  }
Â  Â  headers = {"x-rapidapi-host": "forex-factory-scraper1.p.rapidapi.com", "x-rapidapi-key": api_key}
Â  Â  try:
Â  Â  Â  Â  response = requests.get(url, headers=headers, params=querystring)
Â  Â  Â  Â  data = response.json()
Â  Â  Â  Â  if isinstance(data, list): return data
Â  Â  Â  Â  elif 'data' in data: return data['data']
Â  Â  Â  Â  return []
Â  Â  except Exception as e:
Â  Â  Â  Â  return []

# --- INSTITUTIONAL ALGORITHMS ---

@st.cache_data(ttl=86400)
def get_macro_regime_data(api_key):
Â  Â  if not api_key: return None
Â  Â  try:
Â  Â  Â  Â  fred = Fred(api_key=api_key)
Â  Â  Â  Â  ffr = fred.get_series('FEDFUNDS').iloc[-1]
Â  Â  Â  Â  cpi = fred.get_series('CPIAUCSL').pct_change(12).iloc[-1] * 100
Â  Â  Â  Â  real_rate = ffr - cpi
Â  Â  Â  Â  bias = "BULLISH" if real_rate < 0.5 else "BEARISH"
Â  Â  Â  Â  return {"ffr": ffr, "cpi": cpi, "real_rate": real_rate, "bias": bias}
Â  Â  except Exception:
Â  Â  Â  Â  return None

@st.cache_data(ttl=300)
def calculate_volatility_permission(ticker):
Â  Â  try:
Â  Â  Â  Â  df = yf.download(ticker, period="1y", interval="1d", progress=False)
Â  Â  Â  Â  if df.empty: return None
Â  Â  Â  Â  if isinstance(df.columns, pd.MultiIndex):
Â  Â  Â  Â  Â  Â  high, low, close = df['High'].iloc[:, 0], df['Low'].iloc[:, 0], df['Close'].iloc[:, 0]
Â  Â  Â  Â  else:
Â  Â  Â  Â  Â  Â  high, low, close = df['High'], df['Low'], df['Close']
Â  Â  Â  Â  prev_close = close.shift(1)
Â  Â  Â  Â  tr = pd.concat([high - low, (high - prev_close).abs(), (low - prev_close).abs()], axis=1).max(axis=1)
Â  Â  Â  Â  tr_pct = (tr / close) * 100
Â  Â  Â  Â  tr_pct = tr_pct.dropna()
Â  Â  Â  Â  log_tr = np.log(tr_pct)
Â  Â  Â  Â  forecast_log = log_tr.ewm(alpha=0.94).mean().iloc[-1]
Â  Â  Â  Â  forecast_tr = np.exp(forecast_log)
Â  Â  Â  Â  baseline_series = tr_pct.rolling(20).mean()
Â  Â  Â  Â  baseline = baseline_series.iloc[-1]
Â  Â  Â  Â  return {
Â  Â  Â  Â  Â  Â  "forecast": forecast_tr, "baseline": baseline,
Â  Â  Â  Â  Â  Â  "signal": "TRADE PERMITTED" if forecast_tr > baseline else "NO TRADE / CAUTION",
Â  Â  Â  Â  Â  Â  "is_go": forecast_tr > baseline, "history": tr_pct, "baseline_history": baseline_series
Â  Â  Â  Â  }
Â  Â  except: return None

@st.cache_data(ttl=3600)
def get_options_pdf(opt_ticker):
Â  Â  try:
Â  Â  Â  Â  tk = yf.Ticker(opt_ticker)
Â  Â  Â  Â  exps = tk.options
Â  Â  Â  Â  if len(exps) < 2: return None
Â  Â  Â  Â  target_exp = exps[1]Â 
Â  Â  Â  Â  chain = tk.option_chain(target_exp)
Â  Â  Â  Â  calls = chain.calls
Â  Â  Â  Â  calls = calls[(calls['volume'] > 10) & (calls['openInterest'] > 50)]
Â  Â  Â  Â  if calls.empty: return None
Â  Â  Â  Â  calls['mid'] = (calls['bid'] + calls['ask']) / 2
Â  Â  Â  Â  calls['price'] = np.where((calls['bid']==0), calls['lastPrice'], calls['mid'])
Â  Â  Â  Â  df = calls[['strike', 'price']].sort_values('strike')
Â  Â  Â  Â  spline = UnivariateSpline(df['strike'], df['price'], k=4, s=len(df)*2)
Â  Â  Â  Â  strikes_smooth = np.linspace(df['strike'].min(), df['strike'].max(), 200)
Â  Â  Â  Â  pdf = spline.derivative(n=2)(strikes_smooth)
Â  Â  Â  Â  pdf = np.maximum(pdf, 0)
Â  Â  Â  Â  peak_price = strikes_smooth[np.argmax(pdf)]
Â  Â  Â  Â  return {"strikes": strikes_smooth, "pdf": pdf, "peak": peak_price, "date": target_exp}
Â  Â  except: return None

# --- NEW: COMPREHENSIVE SEASONALITY STATS ---
@st.cache_data(ttl=3600)
def get_seasonality_stats(daily_data):
Â  Â  """Calculates Day, Week, and Month Seasonality"""
Â  Â  try:
Â  Â  Â  Â  df = daily_data.copy()
Â  Â  Â  Â  if isinstance(df.columns, pd.MultiIndex): df = df.droplevel(1, axis=1)
Â  Â  Â  Â Â 
Â  Â  Â  Â  # 1. Prepare Date Features
Â  Â  Â  Â  df['Year'] = df.index.year
Â  Â  Â  Â  df['Month'] = df.index.month
Â  Â  Â  Â  df['Week_Num'] = df.index.to_period('W')
Â  Â  Â  Â  df['Day'] = df.index.day
Â  Â  Â  Â  df['Day_Name'] = df.index.day_name()
Â  Â  Â  Â Â 
Â  Â  Â  Â  # Calculate "Week of Month" (Simple: 1-4/5)
Â  Â  Â  Â  df['Week_of_Month'] = (df['Day'] - 1) // 7 + 1
Â  Â  Â  Â Â 
Â  Â  Â  Â  stats = {}

Â  Â  Â  Â  # --- A. DAY OF WEEK STATS ---
Â  Â  Â  Â  # Only use full weeks for accurate count
Â  Â  Â  Â  valid_weeks = df['Week_Num'].value_counts()
Â  Â  Â  Â  valid_weeks = valid_weeks[valid_weeks >= 2].index
Â  Â  Â  Â  df_weeks = df[df['Week_Num'].isin(valid_weeks)]
Â  Â  Â  Â Â 
Â  Â  Â  Â  weekly_groups = df_weeks.groupby('Week_Num')
Â  Â  Â  Â  high_days = df_weeks.loc[weekly_groups['High'].idxmax()]['Day_Name']
Â  Â  Â  Â  low_days = df_weeks.loc[weekly_groups['Low'].idxmin()]['Day_Name']
Â  Â  Â  Â Â 
Â  Â  Â  Â  days_order = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday']
Â  Â  Â  Â  stats['day_high'] = high_days.value_counts().reindex(days_order, fill_value=0) / len(high_days) * 100
Â  Â  Â  Â  stats['day_low'] = low_days.value_counts().reindex(days_order, fill_value=0) / len(low_days) * 100
Â  Â  Â  Â Â 
Â  Â  Â  Â  # --- B. WEEK OF MONTH STATS ---
Â  Â  Â  Â  # Group by Year-Month to find Monthly High/Low
Â  Â  Â  Â  monthly_groups = df.groupby(['Year', 'Month'])
Â  Â  Â  Â Â 
Â  Â  Â  Â  m_high_idx = monthly_groups['High'].idxmax()
Â  Â  Â  Â  m_low_idx = monthly_groups['Low'].idxmin()
Â  Â  Â  Â Â 
Â  Â  Â  Â  week_highs = df.loc[m_high_idx]['Week_of_Month'].value_counts().sort_index()
Â  Â  Â  Â  week_lows = df.loc[m_low_idx]['Week_of_Month'].value_counts().sort_index()
Â  Â  Â  Â Â 
Â  Â  Â  Â  # Normalize to %
Â  Â  Â  Â  stats['week_high'] = week_highs / week_highs.sum() * 100
Â  Â  Â  Â  stats['week_low'] = week_lows / week_lows.sum() * 100
Â  Â  Â  Â Â 
Â  Â  Â  Â  # --- C. MONTH OF YEAR STATS ---
Â  Â  Â  Â  # Group by Year to find Yearly High/Low
Â  Â  Â  Â  yearly_groups = df.groupby(['Year'])
Â  Â  Â  Â Â 
Â  Â  Â  Â  y_high_idx = yearly_groups['High'].idxmax()
Â  Â  Â  Â  y_low_idx = yearly_groups['Low'].idxmin()
Â  Â  Â  Â Â 
Â  Â  Â  Â  month_names = ['January', 'February', 'March', 'April', 'May', 'June', 'July', 'August', 'September', 'October', 'November', 'December']
Â  Â  Â  Â Â 
Â  Â  Â  Â  # We need to map the result to month names
Â  Â  Â  Â  m_high_counts = df.loc[y_high_idx].index.month_name().value_counts().reindex(month_names, fill_value=0)
Â  Â  Â  Â  m_low_counts = df.loc[y_low_idx].index.month_name().value_counts().reindex(month_names, fill_value=0)
Â  Â  Â  Â Â 
Â  Â  Â  Â  stats['month_high'] = m_high_counts # Raw counts better for yearly (small sample size)
Â  Â  Â  Â  stats['month_low'] = m_low_counts
Â  Â  Â  Â Â 
Â  Â  Â  Â  return stats
Â  Â  except Exception as e:
Â  Â  Â  Â  return None

# --- TECHNICAL CALCULATIONS ---

def calculate_vwap(df):
Â  Â  if df.empty: return df
Â  Â  df['TP'] = (df['High'] + df['Low'] + df['Close']) / 3
Â  Â  df['TPV'] = df['TP'] * df['Volume']
Â  Â  df['VWAP'] = df['TPV'].cumsum() / df['Volume'].cumsum()
Â  Â  return df

def calculate_rsi(series, period=14):
Â  Â  delta = series.diff()
Â  Â  gain = (delta.where(delta > 0, 0)).rolling(window=period).mean()
Â  Â  loss = (-delta.where(delta < 0, 0)).rolling(window=period).mean()
Â  Â  rs = gain / loss
Â  Â  return 100 - (100 / (1 + rs))

@st.cache_data(ttl=3600)
def get_correlation_data():
Â  Â  tickers = {v['ticker']: k for k, v in ASSETS.items()}
Â  Â  tickers[DXY_TICKER] = "US Dollar Index (DXY)"
Â  Â  try:
Â  Â  Â  Â  data = yf.download(list(tickers.keys()), period="1y", interval="1d", progress=False)['Close']
Â  Â  Â  Â  data = data.rename(columns=tickers)
Â  Â  Â  Â  return data
Â  Â  except: return pd.DataFrame()

@st.cache_data(ttl=3600)
def generate_monte_carlo(stock_data, days=126, simulations=1000):
Â  Â  if isinstance(stock_data.columns, pd.MultiIndex): close = stock_data['Close'].iloc[:, 0]
Â  Â  else: close = stock_data['Close']
Â  Â  log_returns = np.log(1 + close.pct_change())
Â  Â  u, var = log_returns.mean(), log_returns.var()
Â  Â  drift = u - (0.5 * var)
Â  Â  stdev = log_returns.std()
Â  Â  price_paths = np.zeros((days + 1, simulations))
Â  Â  price_paths[0] = close.iloc[-1]
Â  Â  daily_returns = np.exp(drift + stdev * np.random.normal(0, 1, (days, simulations)))
Â  Â  for t in range(1, days + 1): price_paths[t] = price_paths[t - 1] * daily_returns[t - 1]
Â  Â  return pd.date_range(start=close.index[-1], periods=days + 1, freq='B'), price_paths

@st.cache_data(ttl=900)
def get_ai_sentiment(api_key, asset_name, news_items):
Â  Â  if not api_key or not news_items: return None
Â  Â  try:
Â  Â  Â  Â  genai.configure(api_key=api_key)
Â  Â  Â  Â  model = genai.GenerativeModel('gemini-pro')
Â  Â  Â  Â  headlines = [f"- {item['title']}" for item in news_items[:8]]
Â  Â  Â  Â  prompt = f"Analyze these headlines for {asset_name}. concise sentiment summary (Bullish/Bearish/Neutral) max 40 words:\n" + "\n".join(headlines)
Â  Â  Â  Â  response = model.generate_content(prompt)
Â  Â  Â  Â  return response.text
Â  Â  except: return None

# --- SIDEBAR ---
with st.sidebar:
Â  Â  st.header("âš™ï¸ Settings")
Â  Â  selected_asset = st.selectbox("Select Asset", list(ASSETS.keys()))
Â  Â  asset_info = ASSETS[selected_asset]
Â  Â  st.markdown("---")
Â  Â  news_key = get_api_key("news_api_key")
Â  Â  fred_key = get_api_key("fred_api_key")
Â  Â  google_key = get_api_key("google_api_key")
Â  Â  rapid_key = get_api_key("rapidapi_key")
Â  Â  st.caption(f"Keys: News {'âœ…' if news_key else 'âŒ'} | FRED {'âœ…' if fred_key else 'âŒ'} | Rapid {'âœ…' if rapid_key else 'âŒ'}")
Â  Â  if st.button("Refresh Data"): st.cache_data.clear()

# --- MAIN DASHBOARD ---
st.title(f"ğŸ“Š {selected_asset} Pro Terminal")

# Fetch Data
daily_data = get_daily_data(asset_info['ticker'])
intraday_data = get_intraday_data(asset_info['ticker'])
macro_regime = get_macro_regime_data(fred_key)
vol_forecast = calculate_volatility_permission(asset_info['ticker'])
options_pdf = get_options_pdf(asset_info['opt_ticker'])
eco_events = get_economic_calendar(rapid_key)

# --- 1. OVERVIEW & MACRO REGIME ---
if not daily_data.empty:
Â  Â  if isinstance(daily_data.columns, pd.MultiIndex): close, high, low, open_p = daily_data['Close'].iloc[:, 0], daily_data['High'].iloc[:, 0], daily_data['Low'].iloc[:, 0], daily_data['Open'].iloc[:, 0]
Â  Â  else: close, high, low, open_p = daily_data['Close'], daily_data['High'], daily_data['Low'], daily_data['Open']

Â  Â  curr = close.iloc[-1]
Â  Â  pct = ((curr - close.iloc[-2]) / close.iloc[-2]) * 100
Â  Â Â 
Â  Â  c1, c2, c3, c4 = st.columns(4)
Â  Â  c1.metric("Price", f"{curr:,.2f}", f"{pct:.2f}%")
Â  Â  c2.metric("High", f"{high.max():,.2f}")
Â  Â  c3.metric("Low", f"{low.min():,.2f}")
Â  Â Â 
Â  Â  if macro_regime:
Â  Â  Â  Â  bias_color = "bullish" if macro_regime['bias'] == "BULLISH" else "bearish"
Â  Â  Â  Â  c4.markdown(f"""
Â  Â  Â  Â  <div style="text-align:center; padding:5px;">
Â  Â  Â  Â  Â  Â  <div style="font-size:0.8em; color:gray;">Macro Regime</div>
Â  Â  Â  Â  Â  Â  <span class='{bias_color}'>{macro_regime['bias']}</span>
Â  Â  Â  Â  Â  Â  <div style="font-size:0.8em;">{macro_regime['real_rate']:.2f}%</div>
Â  Â  Â  Â  </div>
Â  Â  Â  Â  """, unsafe_allow_html=True)
Â  Â  else:
Â  Â  Â  Â  c4.metric("Vol", f"{(close.pct_change().std()* (252**0.5)*100):.2f}%")

Â  Â  fig = go.Figure()
Â  Â  fig.add_trace(go.Candlestick(x=daily_data.index, open=open_p, high=high, low=low, close=close, name="Price"))
Â  Â  fig.update_layout(height=400, template="plotly_dark", paper_bgcolor='rgba(0,0,0,0)', plot_bgcolor='rgba(0,0,0,0)', xaxis_rangeslider_visible=False)
Â  Â  st.plotly_chart(fig, use_container_width=True)

# --- 2. ECONOMIC CALENDAR ---
st.markdown("---")
st.subheader("ğŸ“… Today's Economic Events (USD)")

if eco_events:
Â  Â  cal_data = []
Â  Â  for event in eco_events:
Â  Â  Â  Â  impact = event.get('impact', 'Low')
Â  Â  Â  Â  name = event.get('event_name', 'Unknown')
Â  Â  Â  Â  actual = event.get('actual', '')
Â  Â  Â  Â  forecast = event.get('forecast', '')
Â  Â  Â  Â  previous = event.get('previous', '')
Â  Â  Â  Â Â 
Â  Â  Â  Â  context_msg = ""
Â  Â  Â  Â  if actual and actual != '':
Â  Â  Â  Â  Â  Â  bias = analyze_event_impact(name, actual, forecast, is_actual=True)
Â  Â  Â  Â  Â  Â  if forecast and forecast != '': context_msg = f"Act: {actual} vs Fcst: {forecast} ({bias})"
Â  Â  Â  Â  Â  Â  else: context_msg = f"Act: {actual} (No Fcst)"
Â  Â  Â  Â  elif forecast and forecast != '':
Â  Â  Â  Â  Â  Â  bias = analyze_event_impact(name, forecast, previous, is_actual=False)
Â  Â  Â  Â  Â  Â  if previous and previous != '': context_msg = f"Fcst: {forecast} vs Prev: {previous} ({bias})"
Â  Â  Â  Â  Â  Â  else: context_msg = f"Fcst: {forecast}"
Â  Â  Â  Â  else: context_msg = "Waiting for data..."

Â  Â  Â  Â  cal_data.append({"Time": event.get('time', 'N/A'), "Event": name, "Impact": impact, "Analysis": context_msg})
Â  Â Â 
Â  Â  df_cal = pd.DataFrame(cal_data)
Â  Â  if not df_cal.empty:
Â  Â  Â  Â  def highlight_cols(val):
Â  Â  Â  Â  Â  Â  if 'High' in str(val): return 'color: #ff4b4b; font-weight: bold;'
Â  Â  Â  Â  Â  Â  if 'Bullish' in str(val): return 'color: #00ff00;'
Â  Â  Â  Â  Â  Â  if 'Bearish' in str(val): return 'color: #ff4b4b;'
Â  Â  Â  Â  Â  Â  if 'Mean Reverting' in str(val): return 'color: #cccccc;'
Â  Â  Â  Â  Â  Â  return ''
Â  Â  Â  Â  st.dataframe(df_cal.style.map(highlight_cols), use_container_width=True, hide_index=True)
Â  Â  else: st.info("âœ… No USD events scheduled for today.")
else:
Â  Â  if not rapid_key: st.warning("âš ï¸ **Missing API Key:** Please add `rapidapi_key` to your `secrets.toml` file.")
Â  Â  else: st.info("â„¹ï¸ No Data Found Today.")

# --- 3. VOLATILITY & INTRADAY ---
st.markdown("---")
st.subheader("âš¡ Intraday & Volatility Permissions")

if not intraday_data.empty and vol_forecast:
Â  Â  v1, v2 = st.columns([1, 3])
Â  Â  with v1:
Â  Â  Â  Â  st.markdown("**Daily Volatility Filter**")
Â  Â  Â  Â  badge_class = "vol-go" if vol_forecast['is_go'] else "vol-stop"
Â  Â  Â  Â  st.markdown(f"<span class='{badge_class}'>{vol_forecast['signal']}</span>", unsafe_allow_html=True)
Â  Â  Â  Â  st.markdown(f"<div style='font-size:0.9em; margin-top:5px;'>Expected: {vol_forecast['forecast']:.2f}%<br><span style='color:gray'>Base: {vol_forecast['baseline']:.2f}%</span></div>", unsafe_allow_html=True)
Â  Â  with v2:
Â  Â  Â  Â  hist_tr = vol_forecast['history'].tail(40)
Â  Â  Â  Â  hist_base = vol_forecast['baseline_history'].tail(40)
Â  Â  Â  Â  fig_vol = go.Figure()
Â  Â  Â  Â  fig_vol.add_trace(go.Bar(x=hist_tr.index, y=hist_tr.values, name="Realized TR%", marker_color='#333333'))
Â  Â  Â  Â  fig_vol.add_trace(go.Scatter(x=hist_base.index, y=hist_base.values, name="Baseline", line=dict(color='gray', dash='dot')))
Â  Â  Â  Â  next_day = hist_tr.index[-1] + timedelta(days=1)
Â  Â  Â  Â  f_color = '#00ff00' if vol_forecast['is_go'] else '#ff4b4b'
Â  Â  Â  Â  fig_vol.add_trace(go.Bar(x=[next_day], y=[vol_forecast['forecast']], name="Forecast", marker_color=f_color))
Â  Â  Â  Â  fig_vol.update_layout(title="Volatility Regime", yaxis_title="True Range %", template="plotly_dark", height=250, margin=dict(l=20, r=20, t=30, b=20), paper_bgcolor='rgba(0,0,0,0)', plot_bgcolor='rgba(0,0,0,0)')
Â  Â  Â  Â  st.plotly_chart(fig_vol, use_container_width=True)
Â  Â Â 
Â  Â  if isinstance(intraday_data.columns, pd.MultiIndex): i_close = intraday_data['Close'].iloc[:, 0]; i_vol = intraday_data['Volume'].iloc[:, 0]
Â  Â  else: i_close = intraday_data['Close']; i_vol = intraday_data['Volume']
Â  Â  df_vwap = calculate_vwap(pd.DataFrame({'High': intraday_data['High'].iloc[:,0] if isinstance(intraday_data.columns, pd.MultiIndex) else intraday_data['High'], 'Low': intraday_data['Low'].iloc[:,0] if isinstance(intraday_data.columns, pd.MultiIndex) else intraday_data['Low'], 'Close': i_close, 'Volume': i_vol}))
Â  Â  current_vwap = df_vwap['VWAP'].iloc[-1]
Â  Â  col_dash1, col_dash2, col_dash3 = st.columns(3)
Â  Â  with col_dash1: st.metric("VWAP Bias", "BULLISH" if i_close.iloc[-1] > current_vwap else "BEARISH")
Â  Â  with col_dash2: st.metric("Volume Trend", "Rising" if i_vol.tail(3).mean() > i_vol.mean() else "Falling")
Â  Â  with col_dash3: st.metric("Gap %", f"{((open_p.iloc[-1] - close.iloc[-2])/close.iloc[-2]*100):.2f}%")

# --- 4. TIME-BASED SEASONALITY (UPDATED) ---
st.markdown("---")
st.subheader("ğŸ“… Time-Based Seasonality")
season_stats = get_seasonality_stats(daily_data)

if season_stats:
Â  Â  # We use Tabs for better organization
Â  Â  tab1, tab2, tab3 = st.tabs(["Day of Week", "Week of Month", "Month of Year"])
Â  Â Â 
Â  Â  with tab1:
Â  Â  Â  Â  # Day of Week Chart
Â  Â  Â  Â  fig_d = go.Figure()
Â  Â  Â  Â  fig_d.add_trace(go.Bar(x=season_stats['day_high'].index, y=season_stats['day_high'].values, name='Weekly High', marker_color='#00ff00', opacity=0.7))
Â  Â  Â  Â  fig_d.add_trace(go.Bar(x=season_stats['day_low'].index, y=season_stats['day_low'].values, name='Weekly Low', marker_color='#ff4b4b', opacity=0.7))
Â  Â  Â  Â  fig_d.update_layout(title="Weekly Extremes Distribution", barmode='group', template="plotly_dark", height=300, paper_bgcolor='rgba(0,0,0,0)')
Â  Â  Â  Â  st.plotly_chart(fig_d, use_container_width=True)
Â  Â  Â  Â  st.caption("Shows which Day of the Week typically prints the Weekly High/Low.")
Â  Â  Â  Â Â 
Â  Â  with tab2:
Â  Â  Â  Â  # Week of Month Chart
Â  Â  Â  Â  fig_w = go.Figure()
Â  Â  Â  Â  fig_w.add_trace(go.Bar(x=["Week 1", "Week 2", "Week 3", "Week 4", "Week 5"], y=season_stats['week_high'].values, name='Monthly High', marker_color='#00ff00', opacity=0.7))
Â  Â  Â  Â  fig_w.add_trace(go.Bar(x=["Week 1", "Week 2", "Week 3", "Week 4", "Week 5"], y=season_stats['week_low'].values, name='Monthly Low', marker_color='#ff4b4b', opacity=0.7))
Â  Â  Â  Â  fig_w.update_layout(title="Monthly Extremes by Week", barmode='group', template="plotly_dark", height=300, paper_bgcolor='rgba(0,0,0,0)')
Â  Â  Â  Â  st.plotly_chart(fig_w, use_container_width=True)
Â  Â  Â  Â  st.caption("Shows which Week (1st-5th) typically prints the Monthly High/Low.")

Â  Â  with tab3:
Â  Â  Â  Â  # Month of Year Chart
Â  Â  Â  Â  fig_m = go.Figure()
Â  Â  Â  Â  fig_m.add_trace(go.Bar(x=season_stats['month_high'].index, y=season_stats['month_high'].values, name='Yearly High', marker_color='#00ff00', opacity=0.7))
Â  Â  Â  Â  fig_m.add_trace(go.Bar(x=season_stats['month_low'].index, y=season_stats['month_low'].values, name='Yearly Low', marker_color='#ff4b4b', opacity=0.7))
Â  Â  Â  Â  fig_m.update_layout(title="Yearly Extremes by Month (10Y History)", barmode='group', template="plotly_dark", height=300, paper_bgcolor='rgba(0,0,0,0)')
Â  Â  Â  Â  st.plotly_chart(fig_m, use_container_width=True)
Â  Â  Â  Â  st.caption("Shows which Month typically prints the High/Low of the entire Year.")

# --- 5. INSTITUTIONAL EXPECTATIONS & CONTEXT ---
st.markdown("---")
st.subheader("ğŸ¦ Institutional Expectations & Context")
if options_pdf:
Â  Â  op_col1, op_col2 = st.columns([3, 1])
Â  Â  with op_col1:
Â  Â  Â  Â  fig_opt = go.Figure()
Â  Â  Â  Â  fig_opt.add_trace(go.Scatter(x=options_pdf['strikes'], y=options_pdf['pdf'], fill='tozeroy', name='Implied Prob', line=dict(color='#00d4ff')))
Â  Â  Â  Â  fig_opt.add_vline(x=curr, line_dash="dot", annotation_text="Spot")
Â  Â  Â  Â  fig_opt.add_vline(x=options_pdf['peak'], line_dash="dash", line_color="#d4af37", annotation_text="Expected")
Â  Â  Â  Â  fig_opt.update_layout(template="plotly_dark", height=350, title=f"Options Distribution (Exp: {options_pdf['date']})", paper_bgcolor='rgba(0,0,0,0)')
Â  Â  Â  Â  st.plotly_chart(fig_opt, use_container_width=True)
Â  Â  with op_col2:
Â  Â  Â  Â  st.markdown(f"**Target:** `${options_pdf['peak']:.2f}`")
Â  Â  Â  Â  skew_txt = 'Bullish' if options_pdf['peak'] > curr else 'Bearish'
Â  Â  Â  Â  st.markdown(f"**Skew:** `{skew_txt}`")

pred_dates, pred_paths = generate_monte_carlo(daily_data)
pc1, pc2 = st.columns(2)
with pc1:
Â  Â  fig_pred = go.Figure()
Â  Â  hist_slice = close.tail(90)
Â  Â  fig_pred.add_trace(go.Scatter(x=hist_slice.index, y=hist_slice.values, name='History', line=dict(color='white')))
Â  Â  fig_pred.add_trace(go.Scatter(x=pred_dates, y=np.mean(pred_paths, axis=1), name='Avg Path', line=dict(color='#00ff00', dash='dash')))
Â  Â  fig_pred.update_layout(height=350, template="plotly_dark", paper_bgcolor='rgba(0,0,0,0)', plot_bgcolor='rgba(0,0,0,0)', title="Monte Carlo Drift")
Â  Â  st.plotly_chart(fig_pred, use_container_width=True)
with pc2:
Â  Â  corr_data = get_correlation_data()
Â  Â  if not corr_data.empty:
Â  Â  Â  Â  fig_heat = px.imshow(corr_data.corr(), text_auto=True, color_continuous_scale='RdBu_r', aspect="auto")
Â  Â  Â  Â  fig_heat.update_layout(template="plotly_dark", height=350, paper_bgcolor='rgba(0,0,0,0)', title="Asset Correlations")
Â  Â  Â  Â  st.plotly_chart(fig_heat, use_container_width=True)

# --- 6. CONCLUSION (NEW SECTION) ---
st.markdown("---")
st.subheader("ğŸ Executive Summary")

# Determine Final Bias
bias_score = 0
reasons = []

# 1. Macro
if macro_regime:
Â  Â  if macro_regime['bias'] == "BULLISH":Â 
Â  Â  Â  Â  bias_score += 1
Â  Â  Â  Â  reasons.append("Macro Environment (Real Rates) is Supportive.")
Â  Â  else:Â 
Â  Â  Â  Â  bias_score -= 1
Â  Â  Â  Â  reasons.append("Macro Environment (Real Rates) is Restrictive.")

# 2. Volatility
if vol_forecast and vol_forecast['is_go']:
Â  Â  reasons.append("Volatility Forecast supports breakout/trend strategies.")
else:
Â  Â  reasons.append("Volatility Forecast suggests chop/consolidation (Caution).")

# 3. Options
if options_pdf:
Â  Â  if options_pdf['peak'] > curr:
Â  Â  Â  Â  bias_score += 1
Â  Â  Â  Â  reasons.append(f"Options Market is positioning for higher prices (${options_pdf['peak']:.0f}).")
Â  Â  else:
Â  Â  Â  Â  bias_score -= 1
Â  Â  Â  Â  reasons.append(f"Options Market is positioning for lower prices (${options_pdf['peak']:.0f}).")

# Final Output
final_color = "neutral"
final_text = "NEUTRAL / MIXED"
if bias_score > 0:Â 
Â  Â  final_text = "BULLISH BIAS"
Â  Â  final_color = "bullish"
elif bias_score < 0:Â 
Â  Â  final_text = "BEARISH BIAS"
Â  Â  final_color = "bearish"

st.markdown(f"""
<div style="padding: 20px; border: 1px solid #444; border-radius: 10px; background-color: #1e1e1e;">
Â  Â  <h2 style="text-align:center; margin-top:0;">{selected_asset} Outlook: <span class='{final_color}'>{final_text}</span></h2>
Â  Â  <hr>
Â  Â  <ul>
Â  Â  Â  Â  {''.join([f'<li>{r}</li>' for r in reasons])}
Â  Â  </ul>
Â  Â  <p style="text-align:center; font-size:0.9em; color:gray;"><i>*Generated algorithmically based on Macro, Volatility, and Option Flows.</i></p>
</div>
""", unsafe_allow_html=True)
